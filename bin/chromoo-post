#!/usr/bin/python3

import numpy as np
import pandas as pd
from scipy import stats
import multiprocessing as mp
from functools import partial

from pathlib import Path

import argparse

from chromoo import ConfigHandler
from chromoo.simulation import run_sim_iter
from chromoo.utils import deep_get, readArray, readChromatogram
from chromoo.plotter import Plotter, Subplotter

pd.set_option('display.float_format', lambda x: '%e' % x)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument('config', help='config file to parse and process.')
    ap.add_argument('-n', default=5, type=int, help='Number of best simulations to run')
    ap.add_argument('-m', '--mean', choices=['geometric', 'arithmetic', 'rms'], default='geometric', help='Mode of averaging scores')
    ap.add_argument('--csv', help='CSV file to process')
    ap.add_argument('--hist', default=20, help='Number of bins in histogram plot')

    ap.add_argument('--pop', action='store_true', help='Use pickled population database')
    ap.add_argument('--opt', action='store_true', help='Use pickled opt database')

    args = ap.parse_args()

    config = ConfigHandler()
    config.read(args.config)
    config.load()
    config.construct_simulation()

    postdir = Path('post') 
    postdir.mkdir(exist_ok=True)

    if args.csv: 
        df = pd.read_csv(args.csv)
        df = calculate_mean(df, args.mean, config.objective_names)
        df = df.sort_values(by=[args.mean])

        hist_plot = Plotter(title=args.mean+' mean')
        hist_plot.hist(df[args.mean], args.hist)
        hist_plot.save(postdir / f'histogram_{args.mean}_mean', dpi=600)
        hist_plot.close()

        columns = list(df.columns[0:config.n_par])
        columns.append(df.columns[-1])

        best = df[columns].iloc[0:args.n]
        print(best)

        with mp.Pool(config.nproc) as pool:
            out = pool.map( 
                partial(run_sim_iter, 
                    sim=config.simulation, 
                    parameters=config.parameters, 
                    name=f'final', 
                    tempdir=postdir, 
                    store=True), 
                enumerate(best.values))

        objectives_contain_times = True
        if config.objectives[0].times:
            objectives_contain_times = False

        for i,sim in enumerate(out):

            obj_ref_plot = Plotter( title='title')
            for obj in config.objectives:
                simulated = deep_get(sim.root, obj.path)
                simulated = np.array(simulated).flatten()

                times = deep_get(sim.root, 'output.solution.solution_times')

                if objectives_contain_times:
                    _, reference = readChromatogram(obj.filename)
                else:
                    reference = readArray(obj.filename)

                obj_ref_plot.plot(times, reference)
                obj_ref_plot.plot(times, simulated, ls='dashed')

            obj_ref_plot.save(f"{str(postdir)}/objectives_reference_final_{i:03d}", dpi=600)
            obj_ref_plot.close()

    if args.pop: 
        populations = pd.read_pickle('populations')
        populations = calculate_mean(populations, args.mean, config.objective_names)

        # minned = populations.loc[populations.groupby(['generation'])[args.mean].idxmin()]
        best_mean_score_per_gen = populations.groupby(['generation'])[args.mean].min()
        worst_mean_score_per_gen = populations.groupby(['generation'])[args.mean].max()

        best_mean_score_per_gen_plot = Plotter(title='best_mean_score_per_gen', yscale='log')
        best_mean_score_per_gen_plot.plot(range(len(best_mean_score_per_gen)), best_mean_score_per_gen, label='best')
        best_mean_score_per_gen_plot.plot(range(len(worst_mean_score_per_gen)), worst_mean_score_per_gen, label='worst')
        best_mean_score_per_gen_plot.legend('upper right', (1,1))
        best_mean_score_per_gen_plot.save(f'{str(postdir)}/best_mean_score_per_gen', dpi=600)
        best_mean_score_per_gen_plot.close()

        # populations_best_score_ever_index = populations[args.mean].argmin()
        # print(populations.iloc[populations_best_score_ever_index])

        df = populations.iloc[:,1:].sort_values(by=[args.mean]).drop_duplicates()
        best = df.iloc[0:args.n]
        print(best)

        plot = Subplotter(
            nrows=config.n_obj,
            ncols=config.n_par,
            title='Objectives_Parameters',
            xscale='log',
            yscale='log'
        )

        for i_obj, obj in enumerate(config.objective_names): 
            for i_par, par in enumerate(config.parameter_names): 
                x = populations[par]
                y = populations[obj]

                plot.scatter(x,y, i_obj,i_par, xlabel=par, ylabel=obj)

        plot.save(postdir / "objectives_parameters", dpi=600)
        plot.close()


def calculate_mean(df, mean, columns):
    if mean == 'geometric': 
        df[mean] = stats.gmean(df[columns], axis=1)
    elif mean == 'arithmetic':
        df[mean] = df[columns].mean(axis=1)
    elif mean == 'rms':
        df[mean] = np.sqrt(np.square(df[columns]).mean(axis=1)) 

    return df


if __name__=="__main__":
    main()
